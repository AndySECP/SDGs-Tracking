["Timely detection of an individual\u2019s stress level has the potential to improve stress management, thereby reducing the risk\nof adverse health consequences that may arise due to mismanagement of stress. Recent advances in wearable sensing have\nresulted in multiple approaches to detect and monitor stress with varying levels of accuracy. The most accurate methods,\nhowever, rely on clinical-grade sensors to measure physiological signals; they are often bulky, custom made, and expensive,\nhence limiting their adoption by researchers and the general public. In this article, we explore the viability of commercially\navailable off-the-shelf sensors for stress monitoring. The idea is to be able to use cheap, nonclinical sensors to capture phys-\niological signals and make inferences about the wearer\u2019s stress level based on that data. We describe a system involving a\npopular off-the-shelf heart rate monitor, the Polar H7; we evaluated our system with 26 participants in both a controlled lab\nsetting with three well-validated stress-inducing stimuli and in free-living field conditions. Our analysis shows that using\nthe off-the-shelf sensor alone, we were able to detect stressful events with an F1-score of up to 0.87 in the lab and 0.66 in the\nfield, on par with clinical-grade sensors.", "Existing methods commonly used by behavioral psychologists to quantify and monitor stress levels, such as\nthe Perceived Stress Scale (PSS) [16], have two limitations: (1) they rely on self-report data, and (2) they are\nwindows into moments in time rather than continuous monitors. Moreover, these methods require respondents\nto stop their ongoing activity to fill in the questionnaire. These limitations, although acceptable for retrospective\nstudies of stress, make prospective studies and real-time interventions impossible. For real-time interventions,\nwe need to be able to continuously measure and monitor an individual\u2019s stress level. One approach to enable\nthis sort of real-time measurement and feedback is through the use of wearable sensors.", "With recent advancements in sensor and wearable technologies, it is now possible to continuously collect and\nstream physiological signals for near-real-time analysis. Indeed, researchers are beginning to make progress on\ncontinuous and passive measurement of stress, both in the laboratory and in free-living settings [25, 28, 29, 32,\n33, 38, 42, 48]. Although this prior work introduces and studies a variety of wearable devices and sensors to\ncapture physiological data with a focus on detecting or predicting stress (or stressful events), it relies on custom-\nmade or clinical-grade sensors, which are often bulky, uncomfortable, inaccessible, and/or expensive, making\nthem unappealing or out of reach for many. These limitations prevent large-scale adoption of such sensors by\n(1) researchers who want to observe participant stress in real or near-real time; (2) researchers who want to\nstudy interventions and their effect on other behaviors such as anxiety, smoking cessation or drug abuse; and\n(3) consumers who want to monitor their stress level beyond the clinical setting, in free-living conditions. Toward\nmaking accessible and affordable wearable sensors for stress monitoring possible, in this work we aim to answer\nthe following question: Can we use a commodity device to accurately detect stress?", "\u2022 We compare a variety of data processing methods and their effect on the accuracy of stress inference\nusing a commodity sensor. We demonstrate that some of the typical preprocessing steps used in prior\nwork do not perform equally well for commodity devices.", "\u2022 We make recommendations about the data processing pipeline for the task of stress detection. Although\nour aim was to test applicability for commodity sensors, we show our pipeline also applies to custom-built\nsensors (a galvanic skin response (GSR) sensor) as well. We believe that the recommendations made can", "\u2022 We propose a novel two-layer method for detecting stress, which can account for a participant\u2019s previous\nstress level while determining the current stress level. We show that using the two-layer approach leads to\na notable improvement in stress detection performance. Using only the data from Polar H7 (heart rate and\nR-R interval), we saw an F1-score of 0.88 and 0.66 for detecting stress in the lab and free-living conditions,\nrespectively.", "Improvements in sensors and sensing capabilities over the years have led to a spectrum of prior work in stress\ndetection and assessment. There are multiple methods that have been used for \u201ccontactless\u201d stress measurement,\nsuch as using the user\u2019s voice [35], or using accelerometer-based contextual modeling [24], or phone usage\ndata like Bluetooth and Call/SMS logs [10]; however, we focus on related works using wearable devices for\nphysiology-based stress measurement. Although contactless approaches have some advantages, they also have\nseveral limitations, such as lack of continuous assessment, dependency on personalized models, or the need for\nextensive training across various situations.", "Muaremi et al. [40] used a combination of the Zephyr BioHarness 3.0 [57] and an Empatica E3 [23] for moni-\ntoring stress while sleeping. Gjoreski et al. [26] used both the Empatica E3 and E4 [19] to detect stress in a lab and\nan unconstrained field (free-living) setting. Sano and Picard used the Affectiva Q Sensor along with smartphone\nusage data to predict the PSS scores at the end of the experiment [47]. In all of these works, the sensors they\nused are marketed as \u201chighquality\u201d or \u201cclinicalquality\u201d physiological sensors and hence are too expensive2 to be", "Although the Polar H7 has also been used by Egilmez et al. [18] in UStress, they used it to just get the heart\nrate values (beats per minute) to act as a supplement to their custom GSR sensor for stress prediction in the lab\nsetting. The authors then compared the differences in prediction results by using heart rate information obtained\nfrom a chest-strap sensor (Polar H7) and a smartwatch (from LG). Our work, however, gives insights into the\nfeasibility of using the heart rate and R-R interval data from just a commodity sensor (Polar H7) for being able\nto detect and predict stress both in a controlled lab environment and an unconstrained field scenario.", "We summarize all of the previous work mentioned in this section in Table 1. We report the type of envi-\nronment/situation(s) where the study was conducted, the type of data collected in those studies, the types of\nsensors/devices used, the number of participants, and the results obtained by the authors.", "In what follows, we describe the devices used, the lab and field procedure, and the data collected.", "In addition to the heart rate monitor, for the field study, the participants wore the Amulet wrist device [31]\nto collect activity data and trigger ecological momentary assessment (EMA) prompts. The Amulet also served\nas the data hub to collect the data from the heart rate monitor using Bluetooth Low Energy (BLE). The devices\nused in the study are shown in Figure 1.", "Hovsepian et al. [32] Lab, field Lab train data: 21\nparticipants\nLab test data: 26\nparticipants\nField test data: 20\nparticipants", "is better than with wrist-worn optical sensors [3, 4]. We wanted a heart rate monitor that supported BLE so the\ndata could stream to the Amulet. At the time, there were two popular BLE-capable, chest-mounted heart rate\nmonitors available on the market: the Zephyr HXM and the Polar H7. Both are capable of streaming data and\nfollow the standard Heart Rate Profile protocol specifications.5 Both devices transmit data to the Amulet using\nBLE at 1 Hz. Each data packet consists of one heart rate value and one or more R-R interval values.", "We conducted a preliminary test to compare these heart rate monitors to a popular clinical ECG device\u2014the\nBiopac MP150 [7]. We first measured participants with the Zephyr and the Biopac, and then with the Polar H7 and\nthe Biopac. We then divided the data collected from each device pair into 30-second windows and computed some\nbasic heart rate and R-R interval features. We used a Pearson correlation to compare the feature values between\nthe two devices; the results are shown in Table 2. On inspecting the r -coefficients from the two comparisons, we\nobserve that the features computed from the Biopac were more strongly correlated with the Polar H7 than with\nthe Zephyr HXM. Given the better performance of the Polar H7, we used it for the study.", "3.1.2 The Amulet Wearable Platform. The Amulet is an open source hardware and software platform for writ-\ning energy- and memory-efficient sensing applications [9, 31]. The Amulet has several on-board sensors and pe-\nripherals, including a three-axis accelerometer, light sensor, ambient air temperature sensor, buttons, capacitive\ntouch slider, micro-SD cards, LEDs, and a low-power display. We used the Amulet to act as a data hub to receive\nthe heart rate data using BLE, to record accelerometer data and to prompt Ecological Momentary Assessment\n(EMA) questions to the participant. The Amulet stored all of the sensor data and EMA responses on its internal\nmicro-SD card. The rationale behind using the Amulet for in-the-wild data collection and storage instead of a\nsmartphone was that a wearable would always be on the body of the participant, thus reducing the chances of\ndata loss when the phone was not in range of the person. In addition, the Amulet had additional physical buttons\nthat we were able to map for specific tasks, as described in Section 3.4. Finally, a wearable like Amulet can collect\ndata about the participant\u2019s stress and physical activity even when the smartphone is on the table, in another\nroom, or being used by someone else.", "We first described the details of the study to the participants, and they consented to participate. Next, partic-\nipants put on both the heart rate sensor and the Amulet (which was used solely to to collect the data from the\nheart rate sensor). Once the devices were in place, we began data collection. Each device collected data through-\nout the lab experiment (about 40 minutes). Participants were asked to not move, remove, or interact with the\nsensors in any way.", "At the end of the initial baseline rest period and after each stressor, we asked the participant to verbally rate\nhis or her stress level on a scale from 1 to 5; this was the stress perceived by the user. As the ground truth, we\nlabeled each minute of data collected in the lab as stressed (class = 1) or not stressed (class = 0), based on whether\nthe participant was experiencing a stressor stimulus within that minute.", "For the field study, participants were asked to wear the sensing system for 3 days (at least 8 hours per day) while\ncarrying out their everyday activities. To ensure that the battery of the devices did not drain before the end of\nthe day, we duty cycled the sensing system to record the physiological data for 1 minute every 3 minutes. In\naddition to recording the physiological data, the Amulet prompted the participants to answer EMA questions\nonce every 30 minutes. The participants also had the option to proactively report a \u201cstressful\u201d event by clicking\non a dedicated \u201cevent mark\u201d button. When the participant clicked on this button, the Amulet would record the\ntime as a stressful event, and (in a fraction of such cases) the Amulet would randomly prompt the participant to\ncomplete an EMA questionnaire. If an EMA prompt was triggered due to an event mark, the system would not\ntrigger another EMA again in that 30-minute period, to prevent participant overload.", "While we attempted to collect heart rate variability (HRV), EMA, and accelerometer data for 27 participants in\nthe lab and field, there were problems that led to loss of some data. We ran into a problem with corrupt SD cards,\nwhich led to partial field data loss for 2 participants. We also lost the complete lab data for 1 participant, due to\nthe same SD card problem. Eventually, we ended up with 26 participants for whom we had heart rate data both\nin the lab and the field.", "Figure 3 provides a summary of the data collected; we quantify the amount of lab, field, and EMA data collected\nfrom each participant.", "We now discuss our methods for processing the data, which includes data cleaning, normalization, and feature\ncomputation and selection.", "Once the participants returned the devices to us, we extracted the data from those devices. The Amulet logged\nthe heart rate, R-R interval, accelerometer, EMA, and event mark data to files on the built-in micro-SD memory\ncard. The Amulet encrypted these files as they were written to ensure the data was not compromised in case\na participant lost the Amulet and/or the micro-SD card. We decrypted the data using a Ruby script that also\ngenerates a \u201c.csv\u201d data file for each participant.", "We began with preliminary data cleaning to filter out invalid data points. In this step, we were not trying to handle\noutliers (which may or may not be valid readings) but wanted to remove obviously erroneous data readings. This", "Fig. 3. Summary of the data collected during the field component of the study.", "If the heart rate value was outside a predetermined range, it was considered as noise and removed. We dropped\nboth the heart rate value and any R-R interval values received in that second. Based on previous research con-\nducted to find the maximum human heart rate [21, 51], we set our upper bound to 220 bpm. To determine the\nlower bound, we inspected heart rate data of all participants (visually) to find any noticeable value that would\nseem invalid. The resulting range [30:220] bpm is very conservative; we are confident that any data point outside\nthis range is invalid.", "As reported in Section 3.5, we received 536 event marks when the participants just clicked on a dedicated\nbutton on the Amulet to mark a stressful event. Although participants found it to be easy to mark an event as\nstressful, we fear that it might have been too easy. During the exit interview (i.e., when the participants came\nback to return the devices after the field setting), some of the participants complained about \u201caccidental clicks\u201d on\nthe event mark button, and without an option of undoing the mistake, the Amulet marked the time as a stressful\nevent. We investigated further to determine the extent of the problem. While answering the self-reports, the\nparticipants had to choose their stress level on a scale from 1 to 5. For each participant, we calculated the mean\nscore to all reports they answered. If a participant\u2019s self-report value was higher than his or her mean, then\nwe labeled that instance as a stressed instance (class = 1); otherwise, we labeled it as not stressed (class = 0).\nNow, according to the study design, the participants might randomly receive a prompt to complete a self-report\nafter they click on the event mark button. Of the 536 instances we received, the participants were prompted to\ncomplete the self-report 300 times. Of these 300 instances, the participants chose a stress value greater than their\nindividual mean score only 112 times. This suggests that more than 60% of the time, the participants might have\nclicked on the event mark button by mistake. Without any means to validate if the remaining 236 instances are\ngenuine, we decided not to use the data collected by event marks for training or evaluating our model. We intend\nto fix this problem in future studies.", "Using physiological signals to detect stress has its own drawbacks. The physiological response to mental stress\nis similar to that exhibited due to physical activity and strain. Hence, it is imperative to be able to distinguish\nwhether an observed physiological arousal was due to mental stress or just physical activity. To this end, we\ncollect accelerometer data from the Amulet along with the physiological readings. We use an activity-detection\nalgorithm developed for the Amulet in a study with 14 undergraduate participants [8].", "The activity-detection algorithm uses the accelerometer data and, for every second, infers one of six different\nactivities: lying down, standing, sitting, walking, brisk walking, or running. For every minute in the field data,\nwe determined the dominant activity level\u2014low, medium, or high\u2014based on the activity for each second. If the\nactivity level for a 1-minute window was low (lying down, sitting, or standing), then we included that window\nin our analyses.", "We next use the data remaining after the previous steps to compute features to quantify HRV. We split the data\ninto 1-minute intervals and compute a set of features for each interval. However, before we compute some fea-\ntures for further analyses, it is critical that we (1) handle the effect of outliers in the data and (2) remove any\nparticipant-specific effects on the data, so as to create a generalized model, without any participant dependency.\nThese issues would significantly impact the computed features and eventually the accuracy of the results ob-\ntained. We thus look at each in more detail to understand how the results change with different methods for\nhandling outliers and normalization. All of the previous works we reviewed seem to have just selected some\nmethod for handling outliers (if any) and normalization without taking into account the effect of their choice on\nthe outcome of the metrics under study.", "4.5.1 Outliers. While dealing with outliers in data, the common approaches are (1) leave them in the data,\n(2) reduce the effect the outliers might have, or (3) remove them completely. In our work, we look at each of\nthese approaches and their effect on model training and evaluation. For the first approach, we do nothing to\nthe data (i.e., leave it as is). In the second approach, we use winsorization7 to reduce the effect of outliers on the", "dataset [56]. This approach was also used by some of the previous works, such as cStress [32] and the work by\nGjoreski et al. [26]. For the third approach, we simply remove (trim) data points that we deem as outliers.", "We define outlier as a point that lies beyond a certain threshold above or below the median of the data. For\nour purposes, we set the threshold at three times the median absolute deviation (MAD) within that participant\u2019s\ndata. This choice ensures that we considered only the extreme values as outliers and more than 99% of the data\nis unaltered. Having defined outlier, we establish the upper and lower bounds as follows:", "4.5.2 Normalization. Normalization is important to remove participant-specific effects on the data so as to\nmake the model generalizable to any participant. We tried two different methods for data normalization. With\nphysiological data (e.g., heart rate, Galvanic Skin Response (GSR), skin temperature), each participant has a\ndifferent natural range. Hence, the first normalization method we try is minmax normalization, which simply\ntransforms the values into the range [0, 1]. Given a vector x = (x1,x2, . . . ,xn ), the minmax normalized value for\nthe ith element in x is given by", "4.5.3 Feature Computation. We grouped the normalized data into 1-minute windows. Given the short dura-\ntion of our lab experiments, we wanted to select the shortest possible window size. Esco and Flatt [20] demon-\nstrated that, as compared to 10- or 30-second windows, the features computed in the 60-second window size\nhad the highest agreement with the conventional 5-minute window size. Furthermore, the 1-minute window\nhas been common in physiological monitoring [29, 32, 42].", "For the HRV data, we selected only the time-domain features for our work, as shown in Table 5. All of these\ntime-domain features have been shown to be effective in predicting stressful periods by other researchers [32].", "Unlike HF, which represents parasympathetic activity, LF is less clear. Although some researchers believe\nthat LF represents sympathetic activity, others suggest that it is a mix of both sympathetic and parasympathetic\nactivities [6]. Furthermore, the rationale behind using the LF:HF ratio is that since HF represents parasympathetic\nactivity, a lower HF will increase the ratio, suggesting more stress; however, since the role of LF is not really clear,\nlooking at the ratio might be misleading as well [6]. In addition, for computing LF, we need a window size of\nat least 2 minutes, which would reduce our data size by half. Furthermore, earlier work like cStress found that\ncompared to other time-domain features, and HF, the feature importance of LF and LF:HF is extremely low [32].\nHence we decided to leave out LF and LF:HF features from our work, thus not requiring us to calculate any\nfrequency-domain features.", "In this section, we evaluate our approach. We begin by determining whether we were able to capture a signifi-\ncance difference between the resting and stress-induced periods of the lab component, followed by building and\nevaluating machine-learning models from the lab dataset, and finally using the models built in the lab to infer\nstress/not-stress in the field.", "We first determined whether we could distinguish between resting state and stressful states in the lab data.\nTo this end, we use features computed from the first 10 minutes of the initial rest period and compare them\nindividually to the features computed from the math test, book test, and cold test, respectively. We used Welch\u2019s t-\ntest of unequal variances to determine which features showed any statistically significant differences between the\nresting baseline period and each of the stress-induction periods. As described earlier, we followed three ways of\nhandling outliers and two ways for data normalization, leading to a total of six combinations, as shown in Table 4.\nAcross all six combinations, we observed the maximum number of features showing significant differences in\nthe trim_zscore combination, and for the sake of space, we report results only for that one combination (i.e.,\ntrimmed outliers and z-score normalization).", "Having determined that the features computed from heart rate data (as measured by a readily available, com-\nmercial, off-the-shelf, heart rate monitor (the Polar H7)) showed significant differences between rest and stress-\ninduced periods, we next used these features (mentioned in Table 5) to build machine-learning models designed\nto infer whether the person is stressed or not stressed. Further, during a stressful period, we look at the feasibility\nof differentiating among the three types of stressors: math, book, and cold tests.", "We evaluated each classifier for all the six dataset combinations as mentioned in Table 4 and report three\nmetrics: precision, the fraction of those instances labeled \u201cpositive\u201d that actually are positive instances; recall, the\nfraction of positive instances labeled correctly as positive; and F1-score, the harmonic mean between precision\nand recall. The F1-score is a popular metric in classification problems with one primary class of interest.", "While we did the training and evaluation for each of the six combinations of outlier handling and normalization\nmethods, we observed that outlier_minmax and outlier_zscore consistently performed the worst (on all three\nmetrics: precision, recall, and F1-score) across all six combinations (which was expected, since we did not handle\noutliers in these two combinations, and leaving them as is in the data could have introduced a bias). Hence, we\ndo not report results from those two combinations and show comparisons among the other four options.", "In Table 9, we observe that the best result was achieved by SVM on the trim_zscore combination\u2014that is,\ntrim outliers, then z-score normalization. It is interesting to note that while RF produced a consistent F1-score of\napproximately 0.73 (with varying precision and recall) across the different datasets, SVM showed a wide variation\nof F1-scores: from 0.66 to 0.81.", "8It is important to note that we are not suggesting that the Polar H7 is better than a high-quality or clinical-grade ECG sensor. Instead, we\nbelieve with the right data processing pipeline, commodity devices might suffice for the task of stress detection.", "In this section, we evaluate the models developed in the lab component of the study for stress detection in the\nfield setting. As described previously, in the field component of the study, we asked the participants to wear\nthe devices in their natural environment and prompted several EMA questions to gather the ground truth. One\nof those questions was \u201cRate your stress level over the last 10 minutes.\u201d We specifically asked about the last\n10 minutes rather than a generic \u201cHow stressed do you feel\u201d to reduce the errors in self-reported data due to\nparticipant recall by limiting them to think about only the last 10 minutes.", "To generate the field dataset, we consider the physiological data collected in the 10 minutes leading to the\nself-report answer time. Our sampling strategy was to collect data for 1 minute every 3 minutes (i.e., sample\ncontinuously for 1 minute, then pause for 2 minutes). We took this approach to conserve battery life on the\nAmulet wrist devices. Hence, according to our sampling strategy, we recorded three (sometimes four) 60-second\nwindows corresponding to the 10-minute window prior to each self-report. We computed the features for each\n60-second window and labeled it as stressed (i.e., 1) or not stressed (i.e., 0) based on the response to the 5-point\nLikert scale report from the participant. To binarize the 5-point scale to a simple 1 or 0, for each participant we\ncalculated the median score across all self-reports by that participant; for each report, if the score was greater\nthan the median score, we labeled it as 1 (i.e., stressed), and otherwise, we labeled it as 0 (i.e., not stressed).", "It is important to note that we evaluated the classification results (1) for the entire field data and (2) by removing\nthe activity confounds\u2014that is, by only considering those 60-second windows where the inferred activity level\nwas low.", "To infer stress in the field dataset, we used the models previously generated in the lab setting with the\ntrim_zscore combination, since we achieved the highest precision, recall, and F1-score metrics for that condi-\ntion. We used both the SVM and RF models trained on the lab dataset for classification in the field. Needless\nto say, the field data went through the same preprocessing methods, in this case, trimming outliers followed by\nz-score normalization. The results are shown in Table 14. We observe that removing windows with high physical\nactivity greatly improved the prediction results, leading to a maximum F1-score of 0.62 when we used SVM for", "prediction. Further, by using our two-layer modeling approach, we observed that the F1-score improved to 0.66.\nAlthough the field F1-score reported by our model might seem low, it needs to be considered that we are using\njust a commodity device; unlike previous works that have used high-quality sensors, and fused it with other data\nsources like respiration (in cStress [32]) or GSR, and skin temperature (by Gjoreski et al. [25]), and attain field\nF1-scores of 0.71 and 0.63, respectively, comparable to our results.", "We show that using just a commodity heart rate sensor with a rigorous data processing and feature selection\npipeline, we can accurately infer stress as well as (if not better) than using an ECG device. In previous work,\nsuch as cStress, the authors [32] showed that using just the ECG data, they could infer stress in the lab with\nan F1-score of 0.78, compared to an F1-score of 0.87 in our case, as shown in Figure 7. They do not report field\nresults using just the ECG sensor, so we compare our field results to a biased random classifier as the baseline.\nThe baseline classifier randomly classifies each instance between 0 or 1, based on the probability distribution of\nthe training set, and yields an F1-score of 0.44 in the field. Our approach achieves 52% better results than the\nbaseline.", "Although we show initial evidence that commodity heart rate sensors (at least the Polar H7) can be used for\nstress detection, there is still room for improvement. We anticipate that an increase in the sensor quality and\ntraining for a wider (and a more varied) range of stress-inducing tasks could see an increase in the inference\nresults. In the meantime, we believe that researchers might supplement the heart rate data with other physiolog-\nical data (1) to improve the accuracy or (2) to capture and compare the effect of different physiological signals in\nstress monitoring. Hence, it is important that our data processing pipeline works for other sensor data streams.\nTo this end, we evaluate how well our model performs when we combine data from a GSR device to the data\ncollected from the Polar H7.", "In our study, we also asked the participants to wear a custom-made GSR sensor. We were able to record lab\nand field GSR data from 15 of the 27 participants in the study. We use the heart rate and GSR data from these\n15 participants to build a new combined model and report the change in classification results. The GSR sensor\nused in this work had similar technical specifications as the one developed and evaluated by Pope et al. [44] and\ncould measure electrodermal activity at the ventral wrist for a range of skin conductance values between 0.24\nand 6.0\u03bcS .", "The GSR data we collected also undergoes the same rigorous data cleaning and preprocessing steps; as before,\nwe had six different combinations of outlier handling and normalization, as shown in Table 4. Note, however,\nthat these combinations now contain both heart rate and GSR data for 15 participants.9 As with the heart rate\ndata (which we now refer to as HR data), we follow a similar approach for the merged heart rate and GSR data", "9Since the goal of this work is to evaluate how a commodity heart rate monitor works for stress measurement, we look at the combination\nof heart rate and GSR data. We do not report results or draw comparisons about the performance of just the GSR sensor, as it is beyond the\nscope of this work.", "(which we now refer to as HR-GSR data), starting with feature computation, followed by observing significant\ndifferences, lab data results, and finally the field data results.", "5.4.1 Features for HR-GSR Data. There are two main components to the overall GSR signal. The tonic com-\nponent relates to the slower-acting components and background characteristics of the signal\u2014that is, the overall\nlevel, slow rise, or declines over time. The common measure for the tonic component is the skin conductance\nlevel (SCL), and changes in SCL are known to reflect changes in arousal in the autonomic nervous system. For\neach window, we used the mean, max, min, and standard deviation of the SCL as features. The second component\nof the GSR signal is called the phasic component, which represents the faster-changing elements of the signal\nand is measured by skin reductance response (SCR) [11]. For each window, we compute the total number of SCRs\nin the window (total_SCR), sum of amplitude of the SCRs (sum_amp), sum of SCR durations (sum_dur), and the\ntotal SCR area (auc_SCR). For these latter computations, we use the EDA Explorer tool (with threshold = 0.05\u03bcS)\nmade available by Taylor et al. [52]. Table 15 lists the complete set of GSR features that, in addition to the heart\nrate features computed earlier, were used for the HR-GSR data.", "5.4.2 Capturing Significant Difference Using GSR Data. In Section 5.1, we showed that the features computed\nby the heart rate sensor exhibit statistically significant differences between the baseline rest period and the stress\ninduction periods. We also hypothesized that there might be some residual stress that is being exhibited in the\ninitial minutes of the rest period, and by considering the last 4 minutes of the initial rest period as the baseline,\nwe observed more features that exhibited significant difference. A similar comparison using features computed\nwith the GSR data would help us validate whether our hypothesis was in fact true.", "As in Section 5.1, we report the Welch\u2019s t-test result for the trim_zscore dataset. The results of the t-test using\nthe GSR features, where we consider the entire 10 minutes of the initial rest period as the baseline, are shown in\nTable 16. We observe that only two and one features show significant difference for the book test and the cold\ntest, respectively, suggesting that the GSR features are not able to capture differences between the baseline (of\n10 minutes) and stress induction periods. Next we look at the t-test results by considering only the last 4 minutes\nof the initial rest period as the baseline (shown in Table 17). It is evident that more features exhibit significant", "5.4.3 Evaluation in the Lab. To evaluate the HR-GSR datasets in the lab, we follow an approach similar to the\nlab evaluation in Section 5.2. In this section, we report the results for a LOSO cross validation from the different\ndatasets, using SVM and RF, while considering only the last 4 minutes of the initial rest period as not stressed.\nThe results obtained are shown in Table 18. We observe an increase in the F1-score, once we include the GSR\ndata. Although the best results obtained were from trim_zscore (as for HR-only data), it is interesting to see that\nan RF model performed better than SVM for HR-GSR data (whereas SVM was better for HR data). Next, we used\nthis RF model with our proposed two-layer model and observed that the F1-score improved to 0.94.", "As for HR-only data, we report the feature importance results for the HR-GSR data in Figure 8. From the\nfeature importance plots, we observe that the heart rate features (obtained from a commodity sensor) did play\nan important role in the overall classification model, even when combined with a custom sensor, which suggests\nthat using a custom sensor does not obviate the need for the heart rate sensor.", "5.4.4 Evaluation in the Field. As in the field evaluation of the HR-only data, we use the model built during the\nlab evaluation of the HR-GSR data to predict the stress labels in the field study. We report the results in Table 19.\nWe observe that combination of GSR data and HR data results in an F1-score of 0.70, which improves to 0.73 when\nconsidered in conjunction with the Bayesian network model in our proposed two-layer approach. Based on this\nresult, it seems that trim_zscore can be used as a standard data processing step for accurately detecting stress\nfrom a commodity heart rate monitor, and it can be extended to other sensor streams being used in combination\n(GSR in our case), with similar levels of classification performance as the clinical-grade or custom sensor\u2013based\nsystems used by other researchers in the past.", "Fig. 8. Feature importance representation using RF and linear SVM, using the trim_zscore combination of HR-GSR data,", "Capturing context. Currently, we infer stress with data from a commercial heart rate sensor. However, re-\nsearchers have shown that contextual information can also be useful for inferring stress [37]. With the popu-\nlarity of smartphones and smartwatches, and with the availability of multiple sensors on these devices, context\nmonitoring has become relatively straightforward. In the future, we intend to augment the data obtained from\nthe heart ate sensor with contextual information to identify stress and nonstress periods. If we find that con-\ntextual markers help in identifying stress, context may also be used to predict a stressful situation before it\noccurs. This, in turn, will open new research directions. In our work, we use one aspect about the context of\nthe user\u2014activity, which helps us remove instances in the physiological signals that could be caused by physical\nactivity. Although we use an Amulet to measure activity and administer EMAs, we anticipate that other mobile\nand wearable devices may also be suitable for detecting motion or physical activity context.", "Standardizing the processing pipeline. Prior research using clinical-grade sensors to monitor stress indicates that\nwinsorization is an effective preprocessing approach to handling outliers [26, 32]. For commodity, off-the-shelf\nsensors (Polar H7), we found that the results obtained after performing simple trimming outperformed the results\nobtained after performing winsorization. This observation indicates that data preprocessing and data cleaning\ntechniques that perform well for clinical-grade devices might not perform equally well for commodity devices.\nOne possible explanation for the difference might be the noise present in the data. Since clinical-grade sensors\nare more robust than their consumer-grade counterparts, we expect that they are less prone to environmental\nnoise. It may be that the outliers present in the data obtained from such clinical devices might have some useful\ninformation, making winsorization an effective method. This example is one that could be directly compared to\nprevious works; there might be more such instances where choices for data processing and data modeling might\nlead to differing performance in commodity and clinical devices. Based on our analyses, however, it seems that\ntrimming along with z-score normalization might be a better way to process data for the task of stress detection.\nThe proposed steps led to the best classification results for both HR-only data and HR-GSR data, coming from\ncommodity and custom-made devices. This suggests that our processing pipeline is robust for two device types\nand may be appropriate for other sensor streams as well.", "Usability of chest-based sensors. Some believe that usually chest-band-based sensors might be bulky and un-\ncomfortable, making them a poor choice for continuous usage. We chose to use the Polar H7, a very popular\nproduct, with more than 2,300 five-star reviews on Amazon.10 Further, in our study, after the field session was\nconcluded, we conducted a quantitative and qualitative survey about how the participants felt about our data\ncollection system. When asked if they \u201cfound the system to cause physical discomfort,\u201d participants mostly dis-\nagreed (mean = 1.22 on a scale from 0 to 4, with 0 being strongly disagreed and 4 being strongly agreed); only\nthree participants agreed that the device caused discomfort. On being asked if they \u201ccould have worn the system\nfor a longer period of time,\u201d participants mostly agreed (mean = 2.81). In fact, participants were more concerned\nabout the comfort factor of the wrist-based GSR device. Almost 50% of the participants noted they found the\nGSR device to cause physical discomfort\u2014we believe that this was because of the protruding electrodes.", "10https://www.amazon.com/Polar-Bluetooth-Sensor-Fitness-Tracker/dp/B00NOHWTO6/ref=cm_cr_arp_d_product_top?ie=UTF8.\n11For n = 25 and n = 26, we had 26 and 1 combinations, respectively.\n12The results reported are using the trim_zscore combination of the lab HR data.", "Fig. 10. Comparison of different algorithms for detecting stress in the lab using trim_zscore data for both HR only and\nHR-GSR.", "It is important to note that our current work (along with prior works in this domain) is on offline stress de-\ntection. Our methods leverage the entire dataset for each participant and retrospectively infer stressful events.\nThis approach helps us effectively normalize the participant\u2019s physiological signals because we can easily com-\npute metrics such as mean, standard deviation, min, and max over the data. Normalization over continuously\nstreaming data would be a nontrivial task. One approach would be to calculate local normalization over a sliding\nwindow; another approach is for the system to observe a person\u2019s physiological signals for a brief initial period\nbefore calculating parameters for normalization and subsequent stress detection.", "Comparison with other algorithms. In our work, we focused on two base classifiers: SVM and RF. Gjoreski et al.\n[26] compared performance of several classifiers, including SVM, RF, KNN, and decision tree, and found that\nSVM and RF outperformed all other algorithms. We also made a similar comparison with three additional algo-\nrithms: KNN, multilayer perceptron with ReLU, and decision tree. We compare the performance of the different\nalgorithms for both the HR-only data and HR-GSR data in the lab and show the comparison in Figure 10. Since\nwe were interested in the best-performing classifier, we report results only from the classifier and not when\ncombined with the Bayesian network model in our proposed two-layer approach. We observe from Figure 10\nthat SVM and RF are the top-performing classifiers for both HR-only and HR-GSR data, similar to findings by\nGjoreski et al. [26].", "Unlike current approaches for measuring an individual\u2019s mental stress through the use of expensive clinical-\ngrade sensors, this article explores the possibility of using a cheap commercial wearable device to identify\nwhether an individual is undergoing mental stress in the lab and in free-living settings. As the first work test-\ning the viability of commercial sensors for identifying stress, especially in a field setting, we demonstrated the\npotential of this approach. We also identified several important methodological issues worthy of future work.\nAfter thorough data preprocessing and cleaning steps, we found that techniques reported to perform well for\nclinical-grade devices seem to underperform for consumer-grade devices, as in the example of winsorization.\nWe further proposed a novel two-layer approach for detecting stress by accounting for the stress in the previous\ntime window.", "For the lab study, using just a commodity heart rate monitor, we found that we could identify stressful periods\nwith an F1-score of 0.87. Moreover, in the best case, we could distinguish between three different types of stress-\ninducing tasks with an F1-score of 0.82. In the future, researchers should look beyond distinguishing \u201cstressful\u201d\nperiods from \u201cnonstressful\u201d periods to identifying the type of stress a person is currently undergoing, to enable\nadaptive just-in-time interventions. Additionally, in the lab setting, we found that augmenting the heart rate\nsensor with a GSR sensor helped boost the F1-score from 0.87 to 0.94. For the field study, we found that we could\nidentify stress with an F1-score of 0.66 using heart rate data alone and one of 0.72 using heart rate and GSR data\ntogether. In the future, we plan to use contextual information to improve the stress detection performance.", "[23] Maurizio Garbarino, Matteo Lai, Simone Tognetti, Rosalind Picard, and Daniel Bender. 2014. Empatica E3\u2014A wearable wireless multi-\nsensor device for real-time computerized biofeedback and data acquisition. In Proceedings of the International Conference on Wireless\nMobile Communication and Healthcare. DOI:https://doi.org/10.4108/icst.mobihealth.2014.257418", "[24] Enrique Garcia-Ceja, Venet Osmani, and Oscar Mayora. 2016. Automatic stress detection in working environments from smartphones\u2019\naccelerometer data: A first step. IEEE Journal of Biomedical and Health Informatics 20, 4 (July 2016), 1053\u20131060. DOI:https://doi.org/10.\n1109/JBHI.2015.2446195", "[34] Sylvain Laborde, Emma Mosley, and Julian F. Thayer. 2017. Heart rate variability and cardiac vagal tone in psychophysiologi-\ncal research\u2014Recommendations for experiment planning, data analysis, and data reporting. Frontiers in Psychology 8 (2017), 213.\nDOI:https://doi.org/10.3389/fpsyg.2017.00213", "[48] Hillol Sarker, Inbal Nahum-Shani, Mustafa Al\u2019Absi, Santosh Kumar, Matthew Tyburski, Md M. Rahman, Karen Hovsepian, et al. 2016.\nFinding significant stress episodes in a discontinuous time series of rapidly varying mobile sensor data. In Proceedings of the CHI\nConference on Human Factors in Computing Systems (CHI\u201916). ACM, New York, NY, 4489\u20134501. DOI:https://doi.org/10.1145/2858036.\n2858218", "[52] Sara Taylor, Natasha Jaques, Weixuan Chen, Szymon Fedor, Akane Sano, and Rosalind Picard. 2015. Automatic identification of artifacts\nin electrodermal activity data. In Proceedings of the 2015 37th Annual International Conference of the IEEE Engineering in Medicine and\nBiology Society (EMBC\u201915), Vol. 2015. 1934\u20131937. DOI:https://doi.org/10.1109/EMBC.2015.7318762"]