{"8NATIONAL EDUCATION ASSOCIATION |  1201 16TH ST., NW, WASHINGTON, D.C. 20036Teacher Assessment and Evaluationthat strengthen teaching and thereby increase student growth and learning. By initiating and supporting strategic partnerships with universities, researchers, administrator organizations, and teacher leaders, NEA is poised to accelerate the development and dissemination of effective evaluation models.  USING EVIDENCE OF STUDENT LEARNING Using evidence of student learning and other student outcomes is a fundamental component of the teacher learning and development process. Teachers must understand how their teaching practice in\u02dauences student growth and learning. They need to use that understanding to adjust their practice in ways that allow them to become more effective.  Unfortunately, the use of student learning measures to improve teaching practice has too often translated into using \ufb01value-added\ufb02 analyses of state standardized test scores as the primary, or even sole, means for making summative decisions about teachers. Such use of test data is inappropriate for many reasons that are well-documented. The following are just some of the problems and concerns associated with so-called value-added methodology:A single test score cannot accurately represent student learning. Students need to acquire a broad array of skills, knowledge, and critical thinking tools that a single multiple-choice standardized test cannot re\u02daect.Teachers\u2122 measured effectiveness tends to vary considerably with the use different statistical methodologies. Signi\u02dccant percentages of teachers\u0160more than 50 percent in some cases\u0160who may be rated as \ufb01effective\ufb02 using one method would be rated \ufb01ineffective\ufb02 under another method with the same student test data. In addition, researchers have found that teachers\u2122 effectiveness ratings differ from class to class, from year to year, and even from test to test, even when ratings are within the same content area.Teachers\u2122 ratings are in\u02dauenced by differences among groups of students who are assigned to them. Students are not randomly assigned to teachers, and statistical models cannot fully adjust for the fact that some teachers are assigned a disproportionate number of students who may be exceptionally dif\u02dccult to teach because of poor attendance, homelessness, severe family problems, or other challenges. Some teachers may also have disproportionate numbers of students who are English language learners, have special education needs, or face other roadblocks that tend to distort students\u2122 test scores. It is impossible to fully identify the in\u02dauences of a student\u2122s other teachers and additional factors that affect student performance. No single teacher accounts for all of a student\u2122s learning.Value-added analyses do not provide any information to explain teachers\u2122 performance. They offer no feedback to identify what makes a teacher effective or ineffective.Approximately 70 percent of all teachers are engaged in subject areas for which no test data are available.Over the past several years, numerous studies have concluded that value-added methodology is neither fair enough, nor reliable enough, nor valid enough to be used as a basis for high-stakes decisions about teachers. It is dif\u02dccult, if not impossible, to \u02dcnd any education researchers who support the use of value-added methodologies for high-stakes decisions about teachers, other than several researchers who have developed and promoted the use of  value-added methodologies. Despite the clear limitations of value-added methodologies, many states, districts, and even teacher associations are embracing the use of such methodologies, primarily in pursuit of federal grants during a time when resources are scarce. NEA urges that ":0}